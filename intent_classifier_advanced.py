"""
intent_classifier_advanced.py
-----------------------------
Classificateur d'intention RH avanc√© avec :
- Validation crois√©e et m√©triques de performance
- Hyperparameter tuning automatique
- Comparaison de plusieurs algorithmes
- Sauvegarde des m√©triques et visualisations
- Cache intelligent des mod√®les
"""

import joblib
import json
import os
import sys
import io
from typing import Tuple, Dict, List, Optional, Any
from datetime import datetime
import numpy as np
import pandas as pd

# Encodage UTF-8 pour la sortie
sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')

# Imports sklearn
from sklearn.model_selection import cross_val_score, train_test_split, GridSearchCV
from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import MultinomialNB
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier
from sklearn.pipeline import make_pipeline
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from sklearn.preprocessing import LabelEncoder

# Imports pour visualisation
try:
    import matplotlib.pyplot as plt
    import seaborn as sns
    VISUALIZATION_AVAILABLE = True
except ImportError:
    VISUALIZATION_AVAILABLE = False
    print("‚ö†Ô∏è Matplotlib/Seaborn non disponible - Visualisations d√©sactiv√©es")

class AdvancedIntentClassifier:
    """
    Classificateur d'intention RH avanc√© avec validation crois√©e et m√©triques
    """
    
    def __init__(self, data_path: str = "data/Nestle-HR-FAQ.json", 
                 model_dir: str = "model/", cache_enabled: bool = True):
        """
        Initialise le classificateur avanc√©
        
        Args:
            data_path (str): Chemin vers les donn√©es FAQ
            model_dir (str): R√©pertoire pour sauvegarder les mod√®les
            cache_enabled (bool): Active le cache des mod√®les
        """
        self.data_path = data_path
        self.model_dir = model_dir
        self.cache_enabled = cache_enabled
        
        # Chemins de sortie
        self.model_output = os.path.join(model_dir, "intent_classifier.pkl")
        self.metrics_output = os.path.join(model_dir, "classification_metrics.json")
        self.report_output = os.path.join(model_dir, "classification_report.txt")
        
        # Cr√©er le r√©pertoire de sortie
        os.makedirs(model_dir, exist_ok=True)
        
        # Algorithmes disponibles
        self.algorithms = {
            'logistic_regression': LogisticRegression(max_iter=1000),
            'naive_bayes': MultinomialNB(),
            'svm': SVC(kernel='linear', probability=True),
            'random_forest': RandomForestClassifier(n_estimators=100, random_state=42)
        }
        
        # Param√®tres pour GridSearch
        self.param_grids = {
            'logistic_regression': {
                'logisticregression__C': [0.1, 1, 10, 100],
                'logisticregression__solver': ['liblinear', 'lbfgs']
            },
            'naive_bayes': {
                'multinomialnb__alpha': [0.1, 0.5, 1.0, 2.0]
            },
            'svm': {
                'svc__C': [0.1, 1, 10],
                'svc__gamma': ['scale', 'auto']
            },
            'random_forest': {
                'randomforestclassifier__n_estimators': [50, 100, 200],
                'randomforestclassifier__max_depth': [10, 20, None]
            }
        }
        
        # Stockage des r√©sultats
        self.results = {}
        self.best_model = None
        self.best_algorithm = None
        self.label_encoder = LabelEncoder()

    def charger_donnees(self) -> Tuple[List[str], List[str]]:
        """
        Charge les donn√©es FAQ avec validation
        
        Returns:
            Tuple[List[str], List[str]]: Questions et th√®mes correspondants
            
        Raises:
            FileNotFoundError: Si le fichier n'existe pas
            ValueError: Si la structure des donn√©es est invalide
        """
        print("üìä Chargement des donn√©es FAQ...")
        
        try:
            with open(self.data_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            if "faq" not in data:
                raise ValueError("Structure JSON invalide - cl√© 'faq' manquante")
            
            questions, themes = [], []
            theme_counts = {}
            
            for theme, items in data["faq"].items():
                theme_count = 0
                for item in items:
                    question = item.get("question", "").strip()
                    if question:  # Ignorer les questions vides
                        questions.append(question)
                        themes.append(theme)
                        theme_count += 1
                
                theme_counts[theme] = theme_count
            
            # Afficher les statistiques
            print(f"‚úÖ {len(questions)} questions charg√©es")
            print(f"üìã {len(theme_counts)} th√®mes d√©tect√©s :")
            for theme, count in sorted(theme_counts.items()):
                print(f"   - {theme}: {count} questions")
            
            return questions, themes
            
        except FileNotFoundError:
            print(f"‚ùå Fichier non trouv√© : {self.data_path}")
            raise
        except json.JSONDecodeError as e:
            print(f"‚ùå Erreur JSON : {e}")
            raise
        except Exception as e:
            print(f"‚ùå Erreur inattendue : {e}")
            raise

    def verifier_cache_modele(self) -> bool:
        """
        V√©rifie si un mod√®le en cache est disponible et valide
        
        Returns:
            bool: True si le cache est valide
        """
        if not self.cache_enabled:
            return False
        
        try:
            # V√©rifier l'existence des fichiers
            if not os.path.exists(self.model_output):
                return False
            
            # V√©rifier la date de modification
            model_time = os.path.getmtime(self.model_output)
            data_time = os.path.getmtime(self.data_path)
            
            if model_time < data_time:
                print("‚ö†Ô∏è Donn√©es plus r√©centes que le mod√®le - R√©entra√Ænement n√©cessaire")
                return False
            
            # Charger et valider le mod√®le
            model = joblib.load(self.model_output)
            if hasattr(model, 'predict'):
                print("‚úÖ Mod√®le en cache valide trouv√©")
                return True
            
            return False
            
        except Exception as e:
            print(f"‚ö†Ô∏è Erreur lors de la v√©rification du cache : {e}")
            return False

    def evaluer_modele(self, model, X_train, X_test, y_train, y_test, 
                      algorithm_name: str) -> Dict[str, Any]:
        """
        √âvalue un mod√®le avec des m√©triques compl√®tes
        
        Args:
            model: Mod√®le entra√Æn√©
            X_train, X_test: Donn√©es d'entra√Ænement et de test
            y_train, y_test: Labels d'entra√Ænement et de test
            algorithm_name (str): Nom de l'algorithme
            
        Returns:
            Dict[str, Any]: M√©triques de performance
        """
        print(f"üîç √âvaluation du mod√®le {algorithm_name}...")
        
        # Pr√©dictions
        y_pred_train = model.predict(X_train)
        y_pred_test = model.predict(X_test)
        
        # M√©triques de base
        train_accuracy = accuracy_score(y_train, y_pred_train)
        test_accuracy = accuracy_score(y_test, y_pred_test)
        
        # Validation crois√©e
        cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy')
        
        # Rapport de classification
        class_report = classification_report(y_test, y_pred_test, output_dict=True)
        
        # Matrice de confusion
        conf_matrix = confusion_matrix(y_test, y_pred_test)
        
        results = {
            'algorithm': algorithm_name,
            'train_accuracy': float(train_accuracy),
            'test_accuracy': float(test_accuracy),
            'cv_mean': float(cv_scores.mean()),
            'cv_std': float(cv_scores.std()),
            'cv_scores': cv_scores.tolist(),
            'classification_report': class_report,
            'confusion_matrix': conf_matrix.tolist(),
            'overfitting_score': float(train_accuracy - test_accuracy),
            'timestamp': datetime.now().isoformat()
        }
        
        print(f"   ‚úÖ Pr√©cision test : {test_accuracy:.3f}")
        print(f"   ‚úÖ CV moyenne : {cv_scores.mean():.3f} (¬±{cv_scores.std():.3f})")
        
        return results

    def optimiser_hyperparametres(self, algorithm_name: str, model, 
                                 X_train, y_train) -> Any:
        """
        Optimise les hyperparam√®tres avec GridSearchCV
        
        Args:
            algorithm_name (str): Nom de l'algorithme
            model: Mod√®le √† optimiser
            X_train, y_train: Donn√©es d'entra√Ænement
            
        Returns:
            Meilleur mod√®le optimis√©
        """
        if algorithm_name not in self.param_grids:
            print(f"‚ö†Ô∏è Pas d'optimisation d√©finie pour {algorithm_name}")
            return model
        
        print(f"üîß Optimisation des hyperparam√®tres pour {algorithm_name}...")
        
        # Cr√©er le pipeline
        pipeline = make_pipeline(TfidfVectorizer(), self.algorithms[algorithm_name])
        
        # GridSearchCV
        grid_search = GridSearchCV(
            pipeline,
            self.param_grids[algorithm_name],
            cv=3,  # R√©duit pour acc√©l√©rer
            scoring='accuracy',
            n_jobs=-1,
            verbose=0
        )
        
        grid_search.fit(X_train, y_train)
        
        print(f"   ‚úÖ Meilleur score : {grid_search.best_score_:.3f}")
        print(f"   ‚úÖ Meilleurs param√®tres : {grid_search.best_params_}")
        
        return grid_search.best_estimator_

    def comparer_algorithmes(self, questions: List[str], themes: List[str]) -> Dict[str, Any]:
        """
        Compare plusieurs algorithmes de classification
        
        Args:
            questions (List[str]): Questions FAQ
            themes (List[str]): Th√®mes correspondants
            
        Returns:
            Dict[str, Any]: R√©sultats de comparaison
        """
        print("üèÜ Comparaison des algorithmes de classification...")
        print("=" * 60)
        
        # Diviser les donn√©es
        X_train, X_test, y_train, y_test = train_test_split(
            questions, themes, test_size=0.2, random_state=42, stratify=themes
        )
        
        results = {}
        
        for algorithm_name, algorithm in self.algorithms.items():
            try:
                # Cr√©er le pipeline
                pipeline = make_pipeline(TfidfVectorizer(), algorithm)
                
                # Optimiser les hyperparam√®tres
                optimized_model = self.optimiser_hyperparametres(
                    algorithm_name, pipeline, X_train, y_train
                )
                
                # Entra√Æner le mod√®le optimis√©
                optimized_model.fit(X_train, y_train)
                
                # √âvaluer le mod√®le
                results[algorithm_name] = self.evaluer_modele(
                    optimized_model, X_train, X_test, y_train, y_test, algorithm_name
                )
                
                # Garder le mod√®le pour comparaison
                results[algorithm_name]['model'] = optimized_model
                
            except Exception as e:
                print(f"‚ùå Erreur avec {algorithm_name}: {e}")
                continue
        
        # Trouver le meilleur mod√®le
        if results:
            best_algorithm = max(results.keys(), 
                               key=lambda x: results[x]['cv_mean'])
            
            self.best_algorithm = best_algorithm
            self.best_model = results[best_algorithm]['model']
            
            print("=" * 60)
            print(f"üèÜ Meilleur algorithme : {best_algorithm}")
            print(f"üéØ Score CV : {results[best_algorithm]['cv_mean']:.3f}")
            print("=" * 60)
        
        return results

    def sauvegarder_resultats(self, results: Dict[str, Any]):
        """
        Sauvegarde les r√©sultats et m√©triques
        
        Args:
            results (Dict[str, Any]): R√©sultats de comparaison
        """
        print("üíæ Sauvegarde des r√©sultats...")
        
        # Pr√©parer les donn√©es pour la sauvegarde (sans les mod√®les)
        save_results = {}
        for algo, data in results.items():
            save_results[algo] = {k: v for k, v in data.items() if k != 'model'}
        
        # Sauvegarder les m√©triques JSON
        with open(self.metrics_output, 'w', encoding='utf-8') as f:
            json.dump(save_results, f, indent=2, ensure_ascii=False)
        
        # Sauvegarder le meilleur mod√®le
        if self.best_model:
            joblib.dump(self.best_model, self.model_output)
            print(f"‚úÖ Meilleur mod√®le sauv√© : {self.model_output}")
        
        # G√©n√©rer le rapport texte
        self.generer_rapport_texte(save_results)
        
        print(f"‚úÖ M√©triques sauv√©es : {self.metrics_output}")

    def generer_rapport_texte(self, results: Dict[str, Any]):
        """
        G√©n√®re un rapport texte d√©taill√©
        
        Args:
            results (Dict[str, Any]): R√©sultats de comparaison
        """
        with open(self.report_output, 'w', encoding='utf-8') as f:
            f.write("RAPPORT DE CLASSIFICATION D'INTENTION RH\n")
            f.write("=" * 50 + "\n\n")
            f.write(f"Date de g√©n√©ration : {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"Fichier de donn√©es : {self.data_path}\n\n")
            
            # R√©sum√© des algorithmes
            f.write("COMPARAISON DES ALGORITHMES\n")
            f.write("-" * 30 + "\n")
            
            for algo, data in results.items():
                f.write(f"\n{algo.upper()}:\n")
                f.write(f"  Pr√©cision test      : {data['test_accuracy']:.3f}\n")
                f.write(f"  Validation crois√©e  : {data['cv_mean']:.3f} (¬±{data['cv_std']:.3f})\n")
                f.write(f"  Score overfitting   : {data['overfitting_score']:.3f}\n")
            
            # Meilleur mod√®le
            if self.best_algorithm:
                f.write(f"\nMEILLEUR MOD√àLE : {self.best_algorithm}\n")
                f.write("-" * 30 + "\n")
                best_data = results[self.best_algorithm]
                f.write(f"Score final : {best_data['cv_mean']:.3f}\n")
        
        print(f"‚úÖ Rapport g√©n√©r√© : {self.report_output}")

    def generer_visualisations(self, results: Dict[str, Any]):
        """
        G√©n√®re des visualisations des r√©sultats
        
        Args:
            results (Dict[str, Any]): R√©sultats de comparaison
        """
        if not VISUALIZATION_AVAILABLE:
            print("‚ö†Ô∏è Visualisations non disponibles - Modules manquants")
            return
        
        print("üìà G√©n√©ration des visualisations...")
        
        # Cr√©er le r√©pertoire de visualisations
        vis_dir = os.path.join(self.model_dir, "visualizations")
        os.makedirs(vis_dir, exist_ok=True)
        
        # 1. Comparaison des algorithmes
        algorithms = list(results.keys())
        cv_means = [results[algo]['cv_mean'] for algo in algorithms]
        test_accuracies = [results[algo]['test_accuracy'] for algo in algorithms]
        
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))
        
        # Graphique 1 : Scores de validation crois√©e
        bars1 = ax1.bar(algorithms, cv_means, color='skyblue', alpha=0.7)
        ax1.set_title('Scores de Validation Crois√©e')
        ax1.set_ylabel('Score CV')
        ax1.set_ylim(0, 1)
        plt.setp(ax1.get_xticklabels(), rotation=45, ha='right')
        
        # Ajouter les valeurs sur les barres
        for bar, value in zip(bars1, cv_means):
            ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,
                    f'{value:.3f}', ha='center', va='bottom')
        
        # Graphique 2 : Pr√©cision sur test
        bars2 = ax2.bar(algorithms, test_accuracies, color='lightgreen', alpha=0.7)
        ax2.set_title('Pr√©cision sur Test')
        ax2.set_ylabel('Pr√©cision')
        ax2.set_ylim(0, 1)
        plt.setp(ax2.get_xticklabels(), rotation=45, ha='right')
        
        for bar, value in zip(bars2, test_accuracies):
            ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,
                    f'{value:.3f}', ha='center', va='bottom')
        
        plt.tight_layout()
        plt.savefig(os.path.join(vis_dir, 'algorithm_comparison.png'), dpi=300, bbox_inches='tight')
        plt.close()
        
        # 2. Matrice de confusion pour le meilleur mod√®le
        if self.best_algorithm:
            best_conf_matrix = np.array(results[self.best_algorithm]['confusion_matrix'])
            
            # R√©cup√©rer les labels uniques
            questions, themes = self.charger_donnees()
            unique_themes = sorted(set(themes))
            
            plt.figure(figsize=(10, 8))
            sns.heatmap(best_conf_matrix, annot=True, fmt='d', cmap='Blues',
                       xticklabels=unique_themes, yticklabels=unique_themes)
            plt.title(f'Matrice de Confusion - {self.best_algorithm}')
            plt.xlabel('Pr√©diction')
            plt.ylabel('R√©alit√©')
            plt.xticks(rotation=45, ha='right')
            plt.yticks(rotation=0)
            plt.tight_layout()
            plt.savefig(os.path.join(vis_dir, 'confusion_matrix.png'), dpi=300, bbox_inches='tight')
            plt.close()
        
        print(f"‚úÖ Visualisations sauv√©es dans : {vis_dir}")

    def entrainer_classifieur_complet(self):
        """
        Pipeline complet d'entra√Ænement avec comparaison d'algorithmes
        """
        print("üöÄ D√©marrage de l'entra√Ænement avanc√© du classifieur...")
        print("=" * 60)
        
        # V√©rifier le cache
        if self.verifier_cache_modele():
            print("‚ö° Utilisation du mod√®le en cache")
            self.best_model = joblib.load(self.model_output)
            return
        
        try:
            # Charger les donn√©es
            questions, themes = self.charger_donnees()
            
            # Comparer les algorithmes
            results = self.comparer_algorithmes(questions, themes)
            
            # Sauvegarder les r√©sultats
            self.sauvegarder_resultats(results)
            
            # G√©n√©rer les visualisations
            self.generer_visualisations(results)
            
            print("\nüéâ Entra√Ænement termin√© avec succ√®s!")
            print(f"üèÜ Meilleur mod√®le : {self.best_algorithm}")
            print(f"üìä Score final : {results[self.best_algorithm]['cv_mean']:.3f}")
            
        except Exception as e:
            print(f"‚ùå Erreur pendant l'entra√Ænement : {e}")
            raise

    def predire_intention(self, question: str) -> Tuple[str, float]:
        """
        Pr√©dit l'intention d'une question
        
        Args:
            question (str): Question √† classifier
            
        Returns:
            Tuple[str, float]: (th√®me pr√©dit, score de confiance)
        """
        if not self.best_model:
            # Charger le mod√®le si pas d√©j√† fait
            if os.path.exists(self.model_output):
                self.best_model = joblib.load(self.model_output)
            else:
                raise ValueError("Aucun mod√®le entra√Æn√© disponible")
        
        # Pr√©dire avec probabilit√©
        theme = self.best_model.predict([question])[0]
        
        # Obtenir la probabilit√© maximale comme score de confiance
        if hasattr(self.best_model, 'predict_proba'):
            proba = self.best_model.predict_proba([question])[0]
            confidence = float(max(proba))
        else:
            confidence = 0.8  # Valeur par d√©faut
        
        return theme, confidence


def main():
    """
    Fonction principale pour l'entra√Ænement du classifieur avanc√©
    """
    print("üéØ Classifieur d'intention RH avanc√©")
    print("=" * 40)
    
    # Initialiser le classifieur
    classifier = AdvancedIntentClassifier()
    
    # Entra√Æner le mod√®le
    classifier.entrainer_classifieur_complet()
    
    # Test rapide
    print("\nüß™ Test rapide du mod√®le...")
    try:
        question_test = "Comment puis-je demander mes cong√©s ?"
        theme, confidence = classifier.predire_intention(question_test)
        print(f"Question : {question_test}")
        print(f"Th√®me pr√©dit : {theme}")
        print(f"Confiance : {confidence:.3f}")
    except Exception as e:
        print(f"‚ö†Ô∏è Erreur lors du test : {e}")


if __name__ == "__main__":
    main()